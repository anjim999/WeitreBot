# ğŸ¤– AI-Powered Support Assistant

A full-stack AI-powered support assistant built with React, Node.js, SQLite, and Google Gemini AI. The assistant answers user questions strictly based on product documentation using RAG (Retrieval-Augmented Generation) with TF-IDF similarity search, maintains session-wise conversation context, and provides real-time streaming responses with live status updates.

![Node.js](https://img.shields.io/badge/Node.js-18+-green) ![React](https://img.shields.io/badge/React-18-blue) ![SQLite](https://img.shields.io/badge/SQLite-3-lightblue) ![Gemini](https://img.shields.io/badge/Gemini_AI-2.0_Flash-purple)

---

## âœ¨ Features

### Core Features
- ğŸ’¬ **AI Chat Interface** â€” Beautiful chat UI with user/assistant message bubbles
- ğŸ“„ **Document-Grounded Answering** â€” AI only answers from `docs.json`, refuses unknown questions
- ğŸ” **RAG with TF-IDF Similarity Search** â€” Finds relevant docs instead of sending full knowledge base
- ğŸ§  **Conversation Memory** â€” Last 5 message pairs as context from SQLite
- ğŸ“ **Session Management** â€” UUID-based sessions stored in localStorage
- ğŸ’¾ **SQLite Persistence** â€” All messages and sessions stored in SQLite database

### Bonus Features
- âš¡ **Real-time Streaming** â€” Word-by-word responses via Server-Sent Events (SSE)
- ğŸ”„ **Live Status Updates** â€” Shows "Searching docs..." â†’ "Analyzing context..." â†’ "Generating..." stages
- ğŸ“ **Markdown Rendering** â€” AI responses rendered with proper formatting
- ğŸ³ **Docker Support** â€” Full Dockerfiles + docker-compose.yml
- ğŸ§ª **Unit Tests** â€” Backend tests with Jest + Supertest
- ğŸ›¡ï¸ **Rate Limiting** â€” Per-IP rate limiting on all endpoints

### UI Features
- ğŸ¨ **Premium Glassmorphic Dark UI** â€” Stunning dark theme with glass effects
- âœ¨ **Smooth Animations** â€” Message entry animations, typing indicator, status pulses
- ğŸ“± **Fully Responsive** â€” Works on desktop, tablet, and mobile
- ğŸ’¡ **Suggestion Chips** â€” Pre-built questions for easy onboarding
- ğŸ“‹ **Session Sidebar** â€” Browse, switch, and delete past conversations
- ğŸ†• **New Chat Button** â€” Start fresh conversations anytime

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | React 18, Vite, TailwindCSS v4, Lucide Icons, React Markdown, Framer Motion |
| **Backend** | Node.js, Express.js |
| **Database** | SQLite (via better-sqlite3) |
| **AI/LLM** | Google Gemini 2.0 Flash |
| **Rate Limiting** | express-rate-limit |
| **Testing** | Jest + Supertest |
| **Containerization** | Docker + docker-compose |

---

## ğŸ“ Project Structure

```
weitre-ai/
â”œâ”€â”€ frontend/                        # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatHeader.jsx      # Header with branding
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.jsx     # Renders all messages
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageItem.jsx     # Individual message bubble
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageInput.jsx    # Input + send button
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TypingIndicator.jsx # Animated typing dots
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ StatusIndicator.jsx # Live status stages
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SuggestionChips.jsx # Quick question suggestions
â”‚   â”‚   â”‚   â””â”€â”€ sidebar/
â”‚   â”‚   â”‚       â””â”€â”€ SessionSidebar.jsx  # Session list + controls
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ ChatPage.jsx           # Main page (orchestrates everything)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ chatService.js         # API calls (axios + fetch for SSE)
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ session.js             # Session ID + timestamp utils
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Root component
â”‚   â”‚   â”œâ”€â”€ main.jsx                   # Entry point
â”‚   â”‚   â””â”€â”€ index.css                  # Design system (Tailwind v4)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                          # Node.js Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ env.js                 # Environment config + validation
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â””â”€â”€ chatController.js      # HTTP request/response handlers
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.js         # Business logic orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ llmService.js          # Gemini AI integration + prompting
â”‚   â”‚   â”‚   â””â”€â”€ ragService.js          # TF-IDF similarity search (RAG)
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ rateLimiter.js         # Per-IP rate limiting
â”‚   â”‚   â”‚   â”œâ”€â”€ errorHandler.js        # Global error handling
â”‚   â”‚   â”‚   â””â”€â”€ validator.js           # Request validation
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ database.js            # SQLite init + schema
â”‚   â”‚   â”‚   â””â”€â”€ queries.js             # All DB query functions
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ docs.json              # Product documentation (18 FAQs)
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ chat.routes.js         # API route definitions
â”‚   â”‚   â”œâ”€â”€ __tests__/
â”‚   â”‚   â”‚   â””â”€â”€ chat.test.js           # Unit tests
â”‚   â”‚   â””â”€â”€ app.js                     # Express server entry
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ jest.config.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docker-compose.yml                # Container orchestration
â””â”€â”€ README.md                         # This file
```

---

## ğŸš€ Quick Start

### Prerequisites
- **Node.js 18+** (check: `node --version`)
- **npm 9+** (check: `npm --version`)
- **Google Gemini API key** â€” Get free at [aistudio.google.com/apikey](https://aistudio.google.com/apikey)

### 1. Clone & Install

```bash
# Clone the repository
git clone <repo-url>
cd weitre-ai

# Install backend dependencies
cd backend
npm install

# Install frontend dependencies
cd ../frontend
npm install
```

### 2. Configure Environment

```bash
# Backend environment
cd backend
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

```env
PORT=5000
NODE_ENV=development
GEMINI_API_KEY=your-actual-gemini-api-key
CLIENT_URL=http://localhost:5173
```

### 3. Run Development Servers

```bash
# Terminal 1 â€” Backend (port 5000)
cd backend
npm run dev

# Terminal 2 â€” Frontend (port 5173)
cd frontend
npm run dev
```

### 4. Open Browser

Visit **[http://localhost:5173](http://localhost:5173)**

---

## ğŸ”‘ API Documentation

### Base URL: `http://localhost:5000/api`

### âœ… POST `/api/chat` â€” Send Message

Send a user message and receive an AI response.

**Request:**
```json
{
    "sessionId": "550e8400-e29b-41d4-a716-446655440000",
    "message": "How can I reset my password?"
}
```

**Response (200):**
```json
{
    "success": true,
    "reply": "To reset your password, go to **Settings > Security > Change Password**...",
    "tokensUsed": 156,
    "docsUsed": [
        { "title": "Reset Password", "score": "0.1823" }
    ]
}
```

**Error (400):**
```json
{
    "success": false,
    "error": "Missing or invalid \"sessionId\". Must be a non-empty string."
}
```

---

### âœ… POST `/api/chat/stream` â€” Send Message (Streaming)

Same as `/api/chat` but returns Server-Sent Events with live status updates.

**Request:** Same as POST `/api/chat`

**Response (SSE stream):**
```
data: {"type":"status","stage":"searching","message":"ğŸ” Searching documentation..."}

data: {"type":"status","stage":"docs_found","message":"ğŸ“„ Found 2 relevant document(s)"}

data: {"type":"status","stage":"analyzing","message":"ğŸ§  Analyzing conversation context..."}

data: {"type":"status","stage":"generating","message":"âœï¸ Generating response..."}

data: {"type":"chunk","content":"To reset"}

data: {"type":"chunk","content":" your password"}

data: {"type":"complete","tokensUsed":156}

data: [DONE]
```

---

### âœ… GET `/api/conversations/:sessionId` â€” Get Conversation

Returns all messages for a session in chronological order.

**Response (200):**
```json
{
    "success": true,
    "sessionId": "550e8400-e29b-41d4-a716-446655440000",
    "messages": [
        {
            "id": 1,
            "session_id": "550e8400...",
            "role": "user",
            "content": "How do I reset my password?",
            "tokens_used": 0,
            "created_at": "2026-02-24 10:30:00"
        },
        {
            "id": 2,
            "session_id": "550e8400...",
            "role": "assistant",
            "content": "To reset your password...",
            "tokens_used": 156,
            "created_at": "2026-02-24 10:30:02"
        }
    ]
}
```

---

### âœ… GET `/api/sessions` â€” List All Sessions

**Response (200):**
```json
{
    "success": true,
    "sessions": [
        {
            "id": "550e8400-e29b-41d4-a716-446655440000",
            "created_at": "2026-02-24 10:30:00",
            "updated_at": "2026-02-24 10:35:00",
            "message_count": 6,
            "first_message": "How do I reset my password?"
        }
    ]
}
```

---

### âœ… DELETE `/api/sessions/:sessionId` â€” Delete Session

Deletes a session and all its messages.

**Response (200):**
```json
{
    "success": true,
    "message": "Session deleted successfully"
}
```

---

### âœ… GET `/health` â€” Health Check

```json
{
    "success": true,
    "status": "healthy",
    "timestamp": "2026-02-24T10:30:00.000Z",
    "uptime": 3600
}
```

---

## ğŸ—„ï¸ Database Schema

### SQLite Database: `support_assistant.db`

#### Table: `sessions`
| Column | Type | Description |
|--------|------|-------------|
| `id` | TEXT (PK) | UUID session identifier |
| `created_at` | DATETIME | Auto-set on creation |
| `updated_at` | DATETIME | Updated on each new message |

#### Table: `messages`
| Column | Type | Description |
|--------|------|-------------|
| `id` | INTEGER (PK) | Auto-incrementing ID |
| `session_id` | TEXT (FK) | References sessions.id |
| `role` | TEXT | "user" or "assistant" |
| `content` | TEXT | Message text |
| `tokens_used` | INTEGER | LLM tokens consumed |
| `created_at` | DATETIME | Auto-set on creation |

**Indexes:**
- `idx_messages_session_id` â€” Fast message lookup by session
- `idx_messages_created_at` â€” Chronological ordering
- `idx_sessions_updated_at` â€” Session list sorting

**Foreign Key:** `messages.session_id â†’ sessions.id` (CASCADE DELETE)

---

## ğŸ” RAG Pipeline

Instead of sending the entire `docs.json` to the LLM, we use **TF-IDF similarity search**:

1. **Indexing** â€” On server start, all documents are tokenized and TF-IDF weights are calculated
2. **Query** â€” User's question is tokenized and stop words are removed
3. **Scoring** â€” Each document is scored against the query using TF-IDF cosine similarity
4. **Retrieval** â€” Top 3 most relevant documents are selected
5. **Injection** â€” Only relevant docs are included in the LLM prompt

This approach:
- âœ… Reduces token usage (only sends relevant docs)
- âœ… Improves answer accuracy (less noise)
- âœ… Scales better with large document sets

---

## ğŸ§ª Running Tests

```bash
cd backend
npm test
```

Tests cover:
- All API endpoints (sessions, chat, conversations)
- Input validation (missing fields)
- Database operations (CRUD, message pairs, limits)
- Session lifecycle (create, query, delete)

---

## ğŸ³ Docker Deployment

```bash
# Build and run both services
docker-compose up --build

# Frontend: http://localhost:80
# Backend:  http://localhost:5000
```

---

## ğŸš€ Deployment (Vercel + Render)

### Frontend â†’ Vercel

1. Push your code to GitHub
2. Go to [vercel.com](https://vercel.com) â†’ Import Project
3. Select the `frontend` folder as the root directory
4. Set Framework: **Vite**
5. Add Environment Variable:
   - `VITE_API_URL` = `https://weitre-ai-backend.onrender.com`
6. Deploy!

### Backend â†’ Render

1. Go to [render.com](https://render.com) â†’ New Web Service
2. Connect your GitHub repo
3. Configure:
   - **Root Directory:** `backend`
   - **Build Command:** `npm ci`
   - **Start Command:** `npm start`
   - **Environment:** Node
4. Add Environment Variables:
   - `GEMINI_API_KEY` = your Gemini API key
   - `CLIENT_URL` = your Vercel frontend URL
   - `NODE_ENV` = `production`
   - `PORT` = `5000`
5. Deploy!

Or use the **Render Blueprint** (`render.yaml` at project root) for one-click setup.

---

## ğŸ”„ CI/CD Pipeline

GitHub Actions workflow (`.github/workflows/ci-cd.yml`) runs on every push:

| Stage | Trigger | Action |
|-------|---------|--------|
| ğŸ§ª **Backend Tests** | Push to any branch | Runs Jest + Supertest |
| ğŸ—ï¸ **Frontend Build** | Push to any branch | Validates Vite build |
| ğŸš€ **Deploy Backend** | Push to `main` only | Triggers Render deploy hook |
| ğŸš€ **Deploy Frontend** | Push to `main` only | Deploys to Vercel |

### Required GitHub Secrets

| Secret | Description |
|--------|-------------|
| `RENDER_DEPLOY_HOOK_URL` | Render deploy hook URL |
| `VERCEL_TOKEN` | Vercel API token |
| `VERCEL_ORG_ID` | Vercel organization ID |
| `VERCEL_PROJECT_ID` | Vercel project ID |

---

## ğŸ“ Assumptions

1. **No authentication required** â€” Sessions are identified by UUID stored in localStorage
2. **Document-only answering** â€” AI strictly refuses questions not covered in `docs.json`
3. **Context window** â€” Last 5 user+assistant message pairs are sent as context to maintain conversation flow
4. **Rate limiting** â€” 100 requests per 15min for general API, 15/min for chat
5. **Session persistence** â€” Sessions persist until explicitly deleted; no auto-expiry
6. **SSE for streaming** â€” Server-Sent Events used for real-time response streaming
7. **Gemini 2.5 Flash** â€” Chosen for fast response times and free tier availability

---

## ğŸŒ Live Demo

- **Frontend:** [https://weitre-ai.vercel.app](https://weitre-ai.vercel.app)
- **Backend:** [https://weitre-ai-backend.onrender.com](https://weitre-ai-backend.onrender.com)

---

Built with â¤ï¸ for the Weitredge AI Assignment
